{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96e5df8-5bda-4ae7-bb3f-f6594d09fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "import nltk\n",
    "#https://github.com/maria-antoniak/little-mallet-wrapper\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from functools import reduce\n",
    "\n",
    "csv = 'Posts_v2.csv'\n",
    "\n",
    "#Reading the CSV file to a dataframe\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "#https://github.com/manghat/python-remove-html-from-csv/blob/master/remove_html.py\n",
    "#Removing HTML characters and spaces from the body column\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>|&.{4};')\n",
    "    cleantext = re.sub(cleanr, '', str(raw_html))\n",
    "    clean = re.sub('\\s+',' ',cleantext)\n",
    "    return html.unescape(clean) # replaces the special characters\n",
    "\n",
    "col = 'clean'\n",
    "data = 'clean_v2'\n",
    "\n",
    "#Adding a new column with the clean text\n",
    "\n",
    "df[data] = df[col].apply(cleanhtml)\n",
    "\n",
    "\n",
    "#https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/10-Topic-Modeling-CSV.html\n",
    "#Preprocessing data with MALLET using Little Mallet Wrapper\n",
    "#Transform all the text to lowercase as well as remove stopwords, punctuation, and numbers\n",
    "\n",
    "df[data] = [little_mallet_wrapper.process_string(text, numbers='remove') for text in df[data]]\n",
    "\n",
    "\n",
    "#https://medium.com/@kurtsenol21/topic-modeling-lda-mallet-implementation-in-python-part-1-c493a5297ad2\n",
    "#Removing stopwords using NLTK\n",
    "\n",
    "list_ = open(\"en.txt\").read().split()\n",
    "\n",
    "stop = stopwords.words('english') + list_\n",
    "\n",
    "#https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "#Adding a new column with NLTK stopwords removed\n",
    "l\n",
    "df[data] = df[data].apply(ambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#https://www.geeksforgeeks.org/python-stemming-words-with-nltk/\n",
    "#https://stackoverflow.com/questions/66847267/how-do-you-apply-porter-stemmer-to-a-pandas-df\n",
    "# Using Porter Stemming to get root words\n",
    "\n",
    "ps = PorterStemmer()\n",
    " \n",
    "# using reduce to apply stemmer to each word and join them back into a string\n",
    "df[data] = df.apply(lambda row: nltk.word_tokenize(row[data]), axis=1)\n",
    "df[data] = [reduce(lambda x, y: x + \" \" + ps.stem(y), words, \"\") for words in df[data]]\n",
    "\n",
    "#Putting the updated dataframe back into a CSV file\n",
    "\n",
    "df.to_csv(csv)\n",
    "\n",
    "#Note: You cannot read multiple XML files into the same CSV file. It overwrites the previous rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a2c82-c7a5-47d9-9e39-3f07b3b17be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
