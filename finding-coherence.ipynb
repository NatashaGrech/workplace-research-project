{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc379f77-0935-4114-9048-5666fd2ce962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "#Reading the data from the three seperate files into dataframes\n",
    "df = pd.read_csv('Posts_v2.csv')\n",
    "\n",
    "df['clean_v2']=df['clean_v2'].fillna(\" \")\n",
    "\n",
    "#https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/10-Topic-Modeling-CSV.html\n",
    "#Extracting the preprocessed data into a variable\n",
    "data = [word_tokenize(text) for text in df['clean_v2']]\n",
    "\n",
    "#https://www.youtube.com/watch?v=TgXLq1XIdA0\n",
    "#Build a dictionary for the corpus\n",
    "corpus_dictionary = gensim.corpora.Dictionary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42538d1-182d-4b8b-b11c-d87c1fd6512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<29555 unique tokens: ['add', 'circumstance', 'overly', 'vague', 'worthwhile']...>\n"
     ]
    }
   ],
   "source": [
    "print(corpus_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8466703b-7c35-4b3b-b613-bf1eca79e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29555\n",
      "47368\n"
     ]
    }
   ],
   "source": [
    "print (len(corpus_dictionary))\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c31c00-f4c8-463c-b970-03fb5cee579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['overly', 'vague', 'add', 'circumstance', 'worthwhile'], ['vacation', 'odd', 'end', 'phone', 'call', 'important', 'resolve', 'involved', 'operation', 'matter', 'degree', 'small', 'common', 'suggestion', 'desire', 'realistic', 'manage', 'office', 'awhile', 'edit', 'focus', 'knowledge', 'transfer', 'redundancy', 'majority', 'daily', 'task', 'vacation', 'expect', 'interruption'], ['negotiate', 'flex', 'agreement', 'agree', 'happy', 'agreement', 'negotiate', 'arrangement', 'supervisor', 'promote', 'slot', 'concern', 'home', 'lot', 'hearing', 'arrangement', 'understand', 'promote', 'arrangement', 'flexible', 'arrangement', 'promote'], ['big', 'buck', 'send', 'resume', 'hyperlink', 'online', 'profile', 'linkedin']]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae12c5f3-dbe3-4fa4-920a-1234d5ca854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the topics\n",
    "\n",
    "df2 = pd.read_csv('topic-state-20-v2.txt', sep=\" \", header=None)\n",
    "df2.columns = [\"doc\", \"source\", \"pos\", \"typeindex\", \"type\", \"topic\"]\n",
    "\n",
    "gf = df2.groupby('topic').agg({'type': lambda x: list(x)})\n",
    "\n",
    "topics = gf['type'].astype(str)\n",
    "\n",
    "topics = topics.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76cd08ba-045a-4b97-9e5f-2552be5f6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[refer, mention, bit, sexist, happen, respond,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[show, efficiently, review, rating, criticize,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[field, student, fresh, college, apply, exam, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[familiar, country, depend, location, live, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[overly, vague, circumstance, worthwhile, reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[recently, lunchtime, rarely, remember, schedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[code, code, ticket, rarely, bit, build, task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[desk, minute, orientation, policy, expect, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[stocker, open, store, bother, pretty, eye, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[recently, change, technical, stack, framework...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    type\n",
       "topic                                                   \n",
       "0      [refer, mention, bit, sexist, happen, respond,...\n",
       "1      [show, efficiently, review, rating, criticize,...\n",
       "2      [field, student, fresh, college, apply, exam, ...\n",
       "3      [familiar, country, depend, location, live, pa...\n",
       "4      [overly, vague, circumstance, worthwhile, reas...\n",
       "5      [recently, lunchtime, rarely, remember, schedu...\n",
       "6      [code, code, ticket, rarely, bit, build, task,...\n",
       "7      [desk, minute, orientation, policy, expect, fl...\n",
       "8      [stocker, open, store, bother, pretty, eye, to...\n",
       "9      [recently, change, technical, stack, framework..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069298f7-25ef-458d-b6f4-4f6053483c77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to interpret topic as either a list of tokens or a list of ids",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoherencemodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel\n\u001b[1;32m----> 3\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mCoherenceModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc_v\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m coherence \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mget_coherence()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoherence Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, coherence)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\coherencemodel.py:214\u001b[0m, in \u001b[0;36mCoherenceModel.__init__\u001b[1;34m(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopics\u001b[49m \u001b[38;5;241m=\u001b[39m topics\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses \u001b[38;5;241m=\u001b[39m processes \u001b[38;5;28;01mif\u001b[39;00m processes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, mp\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\coherencemodel.py:429\u001b[0m, in \u001b[0;36mCoherenceModel.topics\u001b[1;34m(self, topics)\u001b[0m\n\u001b[0;32m    427\u001b[0m new_topics \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m topics:\n\u001b[1;32m--> 429\u001b[0m     topic_token_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_elements_are_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     new_topics\u001b[38;5;241m.\u001b[39mappend(topic_token_ids)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\coherencemodel.py:453\u001b[0m, in \u001b[0;36mCoherenceModel._ensure_elements_are_ids\u001b[1;34m(self, topic)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ids_from_ids)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munable to interpret topic as either a list of tokens or a list of ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: unable to interpret topic as either a list of tokens or a list of ids"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "cm = CoherenceModel(topics=topics, texts=data, dictionary=corpus_dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print('Coherence Score: ', coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936936fa-cfb8-49b1-a485-b7eea31a6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print (len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6e48f-a3fe-432c-be8c-b8be7b4b6c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
